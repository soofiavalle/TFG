{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6887c3",
   "metadata": {},
   "source": [
    "TFG part 5- Sofía Valle López"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b64983",
   "metadata": {},
   "source": [
    "First statistical analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec81ee8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Preview for file: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window8.txt  |  window: 8s\n",
      "   time_peak_to_peak_amp  first_harmonic_p2p\n",
      "0                  0.800               0.517\n",
      "1                  0.787               0.491\n",
      "2                  0.727               0.493\n",
      "3                  3.619               2.620\n",
      "4                  3.376               2.682\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Preview for file: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window15.txt  |  window: 15s\n",
      "   time_peak_to_peak_amp  first_harmonic_p2p\n",
      "0                  0.799               0.455\n",
      "1                  0.786               0.423\n",
      "2                  0.726               0.419\n",
      "3                  3.638               2.506\n",
      "4                  3.378               2.287\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Preview for file: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window30.txt  |  window: 30s\n",
      "   time_peak_to_peak_amp  first_harmonic_p2p\n",
      "0                  0.798               0.321\n",
      "1                  0.790               0.338\n",
      "2                  0.729               0.319\n",
      "3                  3.634               2.141\n",
      "4                  3.382               2.307\n",
      "\n",
      "Saved ONE sheet without global aggregation:\n",
      "  -> C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\stat_results.xlsx  [sheet: analysis1_direct_comparison]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Analysis 1 — Direct comparison (ONE SHEET, NO GLOBAL)\n",
    "# Fix: create Excel if it doesn't exist; append if it does.\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "INPUT_FILES = [\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window8.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window15.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window30.txt\",\n",
    "]\n",
    "OUTPUT_XLSX = r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\stat_results.xlsx\"\n",
    "SHEET_NAME = \"analysis1_direct_comparison\"\n",
    "\n",
    "COLS = [\n",
    "    \"patient\",\"fragment\",\"start_time\",\"unit\",\"window_size_s\",\"num_windows\",\n",
    "    \"time_peak_to_peak_amp\",\"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"\n",
    "]\n",
    "\n",
    "def ensure_dir_for(path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "def read_results(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, comment=\"#\", header=None, names=COLS)\n",
    "    df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], errors=\"coerce\")\n",
    "    num = [\"window_size_s\",\"num_windows\",\"time_peak_to_peak_amp\",\n",
    "           \"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"]\n",
    "    df[num] = df[num].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def bland_altman(x, y):\n",
    "    diff = y - x\n",
    "    bias = np.nanmean(diff)\n",
    "    sd = np.nanstd(diff, ddof=1)\n",
    "    return {\"bias\": bias, \"loa_low\": bias - 1.96*sd, \"loa_high\": bias + 1.96*sd, \"sd_diff\": sd}\n",
    "\n",
    "def simple_linear_regression(x, y):\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x_fit, y_fit = x[mask], y[mask]\n",
    "    if x_fit.size < 2:\n",
    "        return {\"intercept\": np.nan, \"slope\": np.nan, \"r2\": np.nan}\n",
    "    slope, intercept = np.polyfit(x_fit, y_fit, deg=1)\n",
    "    y_pred = intercept + slope*x_fit\n",
    "    ss_res = np.sum((y_fit - y_pred)**2)\n",
    "    ss_tot = np.sum((y_fit - np.mean(y_fit))**2)\n",
    "    r2 = 1 - ss_res/ss_tot if ss_tot != 0 else np.nan\n",
    "    return {\"intercept\": intercept, \"slope\": slope, \"r2\": r2}\n",
    "\n",
    "# --- Build tables ---\n",
    "all_rows = []\n",
    "summary_rows = []\n",
    "\n",
    "for path in INPUT_FILES:\n",
    "    df = read_results(path)\n",
    "    win = int(df[\"window_size_s\"].iloc[0]) if not df[\"window_size_s\"].isna().all() else None\n",
    "    window_label = f\"{win}s\" if win is not None else \"unknown\"\n",
    "\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"Preview for file: {path}  |  window: {window_label}\")\n",
    "    print(df[[\"time_peak_to_peak_amp\", \"first_harmonic_p2p\"]].head())\n",
    "\n",
    "    ref = df[\"time_peak_to_peak_amp\"]\n",
    "    cand = df[\"first_harmonic_p2p\"]\n",
    "\n",
    "    rows = df[[\"patient\",\"fragment\",\"start_time\",\"unit\",\"window_size_s\"]].copy()\n",
    "    rows[\"time_peak_to_peak_amp\"] = ref\n",
    "    rows[\"first_harmonic_p2p\"] = cand\n",
    "    rows[\"abs_diff\"] = (cand - ref).abs()\n",
    "    rows[\"rel_error_pct\"] = 100.0 * (cand - ref) / ref.replace(0, np.nan)\n",
    "    rows[\"source_file\"] = os.path.basename(path)\n",
    "    rows[\"window_label\"] = window_label\n",
    "    all_rows.append(rows)\n",
    "\n",
    "    valid = rows[[\"time_peak_to_peak_amp\",\"first_harmonic_p2p\"]].dropna()\n",
    "    if len(valid) >= 2:\n",
    "        from scipy.stats import pearsonr\n",
    "        r, p = pearsonr(valid[\"time_peak_to_peak_amp\"], valid[\"first_harmonic_p2p\"])\n",
    "        ba = bland_altman(valid[\"time_peak_to_peak_amp\"].to_numpy(),\n",
    "                          valid[\"first_harmonic_p2p\"].to_numpy())\n",
    "        reg = simple_linear_regression(valid[\"first_harmonic_p2p\"].to_numpy(),\n",
    "                                       valid[\"time_peak_to_peak_amp\"].to_numpy())\n",
    "    else:\n",
    "        r = p = np.nan\n",
    "        ba = {\"bias\": np.nan, \"loa_low\": np.nan, \"loa_high\": np.nan, \"sd_diff\": np.nan}\n",
    "        reg = {\"intercept\": np.nan, \"slope\": np.nan, \"r2\": np.nan}\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"window_label\": window_label,\n",
    "        \"n_pairs\": len(valid),\n",
    "        \"pearson_r\": r,\n",
    "        \"pearson_p_value\": p,\n",
    "        \"bland_altman_bias\": ba[\"bias\"],\n",
    "        \"bland_altman_loa_low\": ba[\"loa_low\"],\n",
    "        \"bland_altman_loa_high\": ba[\"loa_high\"],\n",
    "        \"bland_altman_sd_diff\": ba[\"sd_diff\"],\n",
    "        \"mean_abs_diff\": (valid[\"first_harmonic_p2p\"] - valid[\"time_peak_to_peak_amp\"]).abs().mean(),\n",
    "        \"median_abs_diff\": (valid[\"first_harmonic_p2p\"] - valid[\"time_peak_to_peak_amp\"]).abs().median(),\n",
    "        \"mean_rel_error_pct\": (100.0 * (valid[\"first_harmonic_p2p\"] - valid[\"time_peak_to_peak_amp\"])\n",
    "                               / valid[\"time_peak_to_peak_amp\"]).mean(),\n",
    "        \"linreg_intercept\": reg[\"intercept\"],\n",
    "        \"linreg_slope\": reg[\"slope\"],\n",
    "        \"linreg_r2\": reg[\"r2\"]\n",
    "    })\n",
    "\n",
    "all_rows_df = pd.concat(all_rows, ignore_index=True)\n",
    "summary_by_window_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "# --- Write one sheet: create if missing, else append/replace sheet ---\n",
    "ensure_dir_for(OUTPUT_XLSX)\n",
    "excel_exists = os.path.exists(OUTPUT_XLSX)\n",
    "mode = \"a\" if excel_exists else \"w\"\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\", mode=mode,\n",
    "                    if_sheet_exists=(\"replace\" if excel_exists else None)) as writer:\n",
    "    all_rows_df.to_excel(writer, sheet_name=SHEET_NAME, index=False)\n",
    "    startrow = all_rows_df.shape[0] + 2\n",
    "    pd.DataFrame({\"INFO\": [\"SUMMARY_BY_WINDOW (Analysis 1)\"]}) \\\n",
    "        .to_excel(writer, sheet_name=SHEET_NAME, index=False, header=False, startrow=startrow)\n",
    "    startrow += 2\n",
    "    summary_by_window_df.to_excel(writer, sheet_name=SHEET_NAME, index=False, startrow=startrow)\n",
    "\n",
    "print(f\"\\nSaved ONE sheet without global aggregation:\\n  -> {OUTPUT_XLSX}  [sheet: {SHEET_NAME}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e339f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo. Figuras guardadas en: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_MAIN\n",
      "PDF multipágina: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_MAIN\\main_visuals_by_window.pdf\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Visualizaciones principales por ventana (versión mejorada)\n",
    "#   1) Pareado por fragmento (time vs first harmonic)\n",
    "#   2) Scatter con correlación + identidad + regresión\n",
    "#   3) Bland–Altman (freq - time)\n",
    "# Fuente: TXT originales (no usa el Excel)\n",
    "# ============================================================\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# ------------------ RUTAS ------------------\n",
    "INPUT_FILES = [\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window8.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window15.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window30.txt\",\n",
    "]\n",
    "OUTPUT_DIR = r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_MAIN\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------ ESTILO (grande y legible) ------------------\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 120,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"font.size\": 18,\n",
    "    \"axes.titlesize\": 24,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "})\n",
    "\n",
    "# ------------------ COLUMNAS DE LOS .TXT ------------------\n",
    "COLS = [\n",
    "    \"patient\",\"fragment\",\"start_time\",\"unit\",\"window_size_s\",\"num_windows\",\n",
    "    \"time_peak_to_peak_amp\",\"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"\n",
    "]\n",
    "\n",
    "# ------------------ HELPERS ------------------\n",
    "def read_results_txt(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Lee el .txt, ignora cabeceras con '#', tipa columnas y filtra pares válidos.\"\"\"\n",
    "    df = pd.read_csv(path, comment=\"#\", header=None, names=COLS)\n",
    "    df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], errors=\"coerce\")\n",
    "    num = [\"window_size_s\",\"num_windows\",\"time_peak_to_peak_amp\",\n",
    "           \"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"]\n",
    "    df[num] = df[num].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"time_peak_to_peak_amp\", \"first_harmonic_p2p\"]).copy()\n",
    "    return df\n",
    "\n",
    "def label_from_window(df: pd.DataFrame, filename: str) -> str:\n",
    "    \"\"\"Etiqueta limpia del tipo '8s', '15s', '30s'.\"\"\"\n",
    "    if df[\"window_size_s\"].notna().any():\n",
    "        try:\n",
    "            v = int(round(float(df[\"window_size_s\"].dropna().iloc[0])))\n",
    "            return f\"{v}s\"\n",
    "        except Exception:\n",
    "            pass\n",
    "    for cand in (\"8\",\"15\",\"30\"):\n",
    "        if cand in os.path.basename(filename):\n",
    "            return f\"{cand}s\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def simple_linear_regression(x, y):\n",
    "    \"\"\"Ajuste y = a + b·x. Devuelve (a, b, R²).\"\"\"\n",
    "    x = np.asarray(x, float); y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[m], y[m]\n",
    "    if x.size < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    b, a = np.polyfit(x, y, 1)  # slope=b, intercept=a\n",
    "    yhat = a + b*x\n",
    "    ss_res = np.sum((y - yhat)**2)\n",
    "    ss_tot = np.sum((y - np.mean(y))**2)\n",
    "    r2 = np.nan if ss_tot == 0 else 1 - ss_res/ss_tot\n",
    "    return a, b, r2\n",
    "\n",
    "def bland_altman_stats(x, y):\n",
    "    \"\"\"Devuelve (bias, sd, loa_low, loa_high) para diff = (y - x).\"\"\"\n",
    "    x = np.asarray(x, float); y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    d = y[m] - x[m]\n",
    "    if d.size == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    bias = np.nanmean(d)\n",
    "    sd = np.nanstd(d, ddof=1)\n",
    "    return bias, sd, bias - 1.96*sd, bias + 1.96*sd\n",
    "\n",
    "def add_textbox(fig, text, x=0.01, y=0.03):\n",
    "    \"\"\"Anotación legible en caja, pegada al borde inferior-izquierdo del lienzo.\"\"\"\n",
    "    fig.text(x, y, text, fontsize=16,\n",
    "             bbox=dict(facecolor=\"white\", alpha=0.95, edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "\n",
    "def place_legend_below(ax, ncol=2):\n",
    "    \"\"\"\n",
    "    Coloca la leyenda fuera de la gráfica, centrada debajo.\n",
    "    Aumenta el margen inferior para que no se corte.\n",
    "    \"\"\"\n",
    "    # margen inferior amplio para que quepan leyenda + caja de texto\n",
    "    plt.subplots_adjust(bottom=0.28)\n",
    "    ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.18), ncol=ncol, frameon=True)\n",
    "\n",
    "# ------------------ BUCLE PRINCIPAL ------------------\n",
    "png_paths = []\n",
    "\n",
    "for path in INPUT_FILES:\n",
    "    df = read_results_txt(path)\n",
    "    if df.empty:\n",
    "        print(f\"[AVISO] Sin datos válidos en: {path}\")\n",
    "        continue\n",
    "\n",
    "    # Orden para el gráfico pareado\n",
    "    df = df.sort_values([\"start_time\", \"patient\", \"fragment\"]).reset_index(drop=True)\n",
    "    win_label = label_from_window(df, path)\n",
    "\n",
    "    # Arrays\n",
    "    x_idx = np.arange(len(df))           # índice de fragmentos\n",
    "    y_time = df[\"time_peak_to_peak_amp\"].to_numpy()\n",
    "    y_freq = df[\"first_harmonic_p2p\"].to_numpy()\n",
    "\n",
    "    # ------------------ (1) PAREADO POR FRAGMENTO ------------------\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # unir pares\n",
    "    for i in range(len(x_idx)):\n",
    "        ax.plot([x_idx[i], x_idx[i]], [y_time[i], y_freq[i]], linewidth=1)\n",
    "\n",
    "    # puntos (tiempo y primer armónico)\n",
    "    ax.scatter(x_idx, y_time, label=\"Time P2P (mmHg)\", s=70)\n",
    "    ax.scatter(x_idx, y_freq, label=\"First harmonic P2P (mmHg)\", s=70)\n",
    "\n",
    "    ax.set_xlabel(\"Fragments ordered by start_time\")\n",
    "    ax.set_ylabel(\"Amplitude (mmHg)\")\n",
    "    ax.set_title(f\"Paired comparison per fragment — {win_label}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # leyenda fuera, centrada abajo\n",
    "    place_legend_below(ax, ncol=2)\n",
    "\n",
    "    # métricas (caja de texto)\n",
    "    abs_diff = np.abs(y_freq - y_time)\n",
    "    rel_err = 100.0 * (y_freq - y_time) / np.where(y_time == 0, np.nan, y_time)\n",
    "    bias, sd, loa_low, loa_high = bland_altman_stats(y_time, y_freq)\n",
    "    txt = (\n",
    "        f\"Mean |diff| = {np.nanmean(abs_diff):.3f} mmHg    \"\n",
    "        f\"Median |diff| = {np.nanmedian(abs_diff):.3f} mmHg\\n\"\n",
    "        f\"Mean rel. error = {np.nanmean(rel_err):.1f}%    \"\n",
    "        f\"Bias = {bias:.3f} mmHg,  LoA = [{loa_low:.3f}, {loa_high:.3f}] mmHg\"\n",
    "    )\n",
    "    add_textbox(fig, txt, x=0.02, y=0.04)\n",
    "\n",
    "    f1 = os.path.join(OUTPUT_DIR, f\"01_paired_per_fragment_{win_label}.png\")\n",
    "    plt.savefig(f1, bbox_inches=\"tight\"); plt.close()\n",
    "    png_paths.append(f1)\n",
    "\n",
    "    # ------------------ (2) SCATTER + IDENTIDAD + REGRESIÓN ------------------\n",
    "    mask = np.isfinite(y_time) & np.isfinite(y_freq)\n",
    "    r, pval = (np.nan, np.nan)\n",
    "    if mask.sum() >= 2:\n",
    "        r, pval = pearsonr(y_time[mask], y_freq[mask])\n",
    "\n",
    "    a, b, r2 = simple_linear_regression(y_time, y_freq)\n",
    "    xmax = float(np.nanmax(y_time)); ymax = float(np.nanmax(y_freq))\n",
    "    lim = max(xmax, ymax, 0.0)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = plt.gca()\n",
    "    ax.scatter(y_time, y_freq, s=70)\n",
    "    # identidad\n",
    "    ax.plot([0, lim], [0, lim], linestyle=\"--\", linewidth=1)\n",
    "    # regresión\n",
    "    if not (math.isnan(a) or math.isnan(b)):\n",
    "        xline = np.linspace(0, lim, 200)\n",
    "        yline = a + b * xline\n",
    "        ax.plot(xline, yline, linestyle=\"-\", linewidth=1)\n",
    "\n",
    "    ax.set_xlabel(\"Time peak-to-peak amplitude (mmHg)\")\n",
    "    ax.set_ylabel(\"First harmonic P2P (mmHg)\")\n",
    "    ax.set_title(f\"Time vs First Harmonic P2P — {win_label}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # leyenda (opcional); si la añades, también la mando abajo\n",
    "    # ax.legend([\"Identity\", \"Regression\"], loc=\"upper center\", bbox_to_anchor=(0.5, -0.18), ncol=2)\n",
    "\n",
    "    # caja de estadísticas\n",
    "    txt = (f\"Pearson r = {r:.3f},  p = {pval:.3g}\\n\"\n",
    "           f\"Linear fit: y = a + b·x    a = {a:.3f},  b = {b:.3f}\\n\"\n",
    "           f\"R² = {r2:.3f}\")\n",
    "    add_textbox(fig, txt, x=0.02, y=0.04)\n",
    "\n",
    "    f2 = os.path.join(OUTPUT_DIR, f\"02_scatter_time_vs_firstharm_{win_label}.png\")\n",
    "    plt.savefig(f2, bbox_inches=\"tight\"); plt.close()\n",
    "    png_paths.append(f2)\n",
    "\n",
    "    # ------------------ (3) BLAND–ALTMAN ------------------\n",
    "    bias, sd, loa_low, loa_high = bland_altman_stats(y_time, y_freq)\n",
    "    mean_xy = (y_time + y_freq) / 2.0\n",
    "    diff = y_freq - y_time\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = plt.gca()\n",
    "    ax.scatter(mean_xy, diff, s=70)\n",
    "    ax.axhline(bias, linestyle=\"-\", linewidth=1)\n",
    "    ax.axhline(loa_low, linestyle=\"--\", linewidth=1)\n",
    "    ax.axhline(loa_high, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    ax.set_xlabel(\"Mean of methods (mmHg)\")\n",
    "    ax.set_ylabel(\"Difference (freq - time) (mmHg)\")\n",
    "    ax.set_title(f\"Bland–Altman — {win_label}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # caja de estadísticas\n",
    "    txt = (f\"Bias = {bias:.3f} mmHg     SD = {sd:.3f} mmHg\\n\"\n",
    "           f\"LoA = [{loa_low:.3f}, {loa_high:.3f}] mmHg\")\n",
    "    add_textbox(fig, txt, x=0.02, y=0.04)\n",
    "\n",
    "    f3 = os.path.join(OUTPUT_DIR, f\"03_bland_altman_{win_label}.png\")\n",
    "    plt.savefig(f3, bbox_inches=\"tight\"); plt.close()\n",
    "    png_paths.append(f3)\n",
    "\n",
    "# ------------------ PDF MULTIPÁGINA ------------------\n",
    "pdf_path = os.path.join(OUTPUT_DIR, \"main_visuals_by_window.pdf\")\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    for p in png_paths:\n",
    "        img = plt.imread(p)\n",
    "        plt.figure(figsize=(11.69, 8.27))  # A4 apaisado\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        pdf.savefig(bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "print(\"Listo. Figuras guardadas en:\", OUTPUT_DIR)\n",
    "print(\"PDF multipágina:\", pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab28247",
   "metadata": {},
   "source": [
    "Second statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f5bab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Preview for file: final_results_window8.txt | window: 8s\n",
      "   multi_harmonics_peak  first_harmonic_peak\n",
      "0                 0.271                0.259\n",
      "1                 0.263                0.246\n",
      "2                 0.261                0.247\n",
      "3                 1.381                1.310\n",
      "4                 1.392                1.341\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Preview for file: final_results_window15.txt | window: 15s\n",
      "   multi_harmonics_peak  first_harmonic_peak\n",
      "0                 0.237                0.227\n",
      "1                 0.222                0.211\n",
      "2                 0.220                0.209\n",
      "3                 1.317                1.253\n",
      "4                 1.197                1.143\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Preview for file: final_results_window30.txt | window: 30s\n",
      "   multi_harmonics_peak  first_harmonic_peak\n",
      "0                 0.167                0.161\n",
      "1                 0.177                0.169\n",
      "2                 0.166                0.160\n",
      "3                 1.120                1.070\n",
      "4                 1.191                1.153\n",
      "\n",
      "Guardado en: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\stat_results.xlsx  [sheet: analysis2_energy_ratio]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Analysis 2 — Energy ratio (multi/first) con resumen abajo\n",
    "# -> Usa if_sheet_exists=\"overlay\" para escribir dos veces en la misma hoja\n",
    "# ============================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "INPUT_FILES = [\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window8.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window15.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window30.txt\",\n",
    "]\n",
    "OUTPUT_XLSX = r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\stat_results.xlsx\"\n",
    "SHEET_NAME = \"analysis2_energy_ratio\"\n",
    "\n",
    "COLS = [\n",
    "    \"patient\",\"fragment\",\"start_time\",\"unit\",\"window_size_s\",\"num_windows\",\n",
    "    \"time_peak_to_peak_amp\",\"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"\n",
    "]\n",
    "\n",
    "def ensure_dir_for(path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "def read_results(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, comment=\"#\", header=None, names=COLS)\n",
    "    df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], errors=\"coerce\")\n",
    "    num_cols = [\"window_size_s\",\"num_windows\",\"time_peak_to_peak_amp\",\n",
    "                \"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"]\n",
    "    df[num_cols] = df[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "# ---------- Cálculo ----------\n",
    "all_rows, summary_rows = [], []\n",
    "\n",
    "for path in INPUT_FILES:\n",
    "    df = read_results(path)\n",
    "    win = int(df[\"window_size_s\"].iloc[0]) if not df[\"window_size_s\"].isna().all() else None\n",
    "    window_label = f\"{win}s\" if win is not None else \"unknown\"\n",
    "\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"Preview for file: {os.path.basename(path)} | window: {window_label}\")\n",
    "    print(df[[\"multi_harmonics_peak\", \"first_harmonic_peak\"]].head())\n",
    "\n",
    "    ratio = df[\"multi_harmonics_peak\"] / df[\"first_harmonic_peak\"].replace(0, np.nan)\n",
    "\n",
    "    rows = df[[\"patient\",\"fragment\",\"start_time\",\"unit\",\"window_size_s\"]].copy()\n",
    "    rows[\"multi_harmonics_peak\"] = df[\"multi_harmonics_peak\"]\n",
    "    rows[\"first_harmonic_peak\"] = df[\"first_harmonic_peak\"]\n",
    "    rows[\"energy_ratio_R\"]      = ratio\n",
    "    rows[\"source_file\"]         = os.path.basename(path)\n",
    "    rows[\"window_label\"]        = window_label\n",
    "    all_rows.append(rows)\n",
    "\n",
    "    valid_ratio = ratio.dropna()\n",
    "    summary_rows.append({\n",
    "        \"window_label\": window_label,\n",
    "        \"n_pairs\": len(valid_ratio),\n",
    "        \"mean_ratio\": np.nanmean(valid_ratio),\n",
    "        \"median_ratio\": np.nanmedian(valid_ratio),\n",
    "        \"std_ratio\": np.nanstd(valid_ratio, ddof=1),\n",
    "        \"min_ratio\": np.nanmin(valid_ratio),\n",
    "        \"max_ratio\": np.nanmax(valid_ratio),\n",
    "        \"q25_ratio\": np.nanpercentile(valid_ratio, 25),\n",
    "        \"q75_ratio\": np.nanpercentile(valid_ratio, 75),\n",
    "    })\n",
    "\n",
    "all_rows_df = pd.concat(all_rows, ignore_index=True)\n",
    "summary_df   = pd.DataFrame(summary_rows)\n",
    "\n",
    "# ---------- Escritura: detalle + título + resumen ----------\n",
    "ensure_dir_for(OUTPUT_XLSX)\n",
    "\n",
    "# Borra la hoja si ya existe para empezar limpia\n",
    "if os.path.exists(OUTPUT_XLSX):\n",
    "    wb = load_workbook(OUTPUT_XLSX)\n",
    "    if SHEET_NAME in wb.sheetnames:\n",
    "        wb.remove(wb[SHEET_NAME])\n",
    "        wb.save(OUTPUT_XLSX)\n",
    "    wb.close()\n",
    "    mode = \"a\"\n",
    "else:\n",
    "    mode = \"w\"\n",
    "\n",
    "# 👇 CLAVE: if_sheet_exists=\"overlay\" permite escribir otra vez en la misma hoja\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\", mode=mode, if_sheet_exists=\"overlay\") as writer:\n",
    "    # 1) Detalle\n",
    "    all_rows_df.to_excel(writer, sheet_name=SHEET_NAME, index=False)\n",
    "\n",
    "    # 2) Título + Resumen con su propio header, más abajo\n",
    "    ws = writer.sheets[SHEET_NAME]\n",
    "    startrow = all_rows_df.shape[0] + 2   # deja una línea en blanco\n",
    "    ws.cell(row=startrow, column=1, value=\"SUMMARY_BY_WINDOW (Analysis 2)\")\n",
    "    # tabla de resumen (con encabezados) dos filas debajo del título\n",
    "    summary_df.to_excel(writer, sheet_name=SHEET_NAME, index=False, startrow=startrow + 2)\n",
    "\n",
    "print(f\"\\nGuardado en: {OUTPUT_XLSX}  [sheet: {SHEET_NAME}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eef95997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "File: final_results_window8.txt | window: 8s\n",
      "   multi_harmonics_peak  first_harmonic_peak\n",
      "0                 0.271                0.259\n",
      "1                 0.263                0.246\n",
      "2                 0.261                0.247\n",
      "3                 1.381                1.310\n",
      "4                 1.392                1.341\n",
      "Saved: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS2\\hist_ratio_R_8s.png\n",
      "Saved: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS2\\scatter_multi_vs_first_8s.png\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "File: final_results_window15.txt | window: 15s\n",
      "   multi_harmonics_peak  first_harmonic_peak\n",
      "0                 0.237                0.227\n",
      "1                 0.222                0.211\n",
      "2                 0.220                0.209\n",
      "3                 1.317                1.253\n",
      "4                 1.197                1.143\n",
      "Saved: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS2\\hist_ratio_R_15s.png\n",
      "Saved: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS2\\scatter_multi_vs_first_15s.png\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "File: final_results_window30.txt | window: 30s\n",
      "   multi_harmonics_peak  first_harmonic_peak\n",
      "0                 0.167                0.161\n",
      "1                 0.177                0.169\n",
      "2                 0.166                0.160\n",
      "3                 1.120                1.070\n",
      "4                 1.191                1.153\n",
      "Saved: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS2\\hist_ratio_R_30s.png\n",
      "Saved: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS2\\scatter_multi_vs_first_30s.png\n",
      "\n",
      "Listo. Revisa la carpeta: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Visualizaciones del Análisis 2 (por ventana)\n",
    "#   Para cada tamaño de ventana (8s, 15s, 30s) crea:\n",
    "#     (1) Histograma del ratio R = multi / first\n",
    "#     (2) Dispersión: first_harmonic_peak vs multi_harmonics_peak\n",
    "# ============================================================\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# ------------------ RUTAS ------------------\n",
    "INPUT_FILES = [\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window8.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window15.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window30.txt\",\n",
    "]\n",
    "OUTPUT_DIR = r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS2\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------ COLUMNAS DE LOS .TXT ------------------\n",
    "COLS = [\n",
    "    \"patient\",\"fragment\",\"start_time\",\"unit\",\"window_size_s\",\"num_windows\",\n",
    "    \"time_peak_to_peak_amp\",\"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"\n",
    "]\n",
    "\n",
    "# ------------------ ESTILO ------------------\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 120,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"font.size\": 18,\n",
    "    \"axes.titlesize\": 24,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 16,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "})\n",
    "\n",
    "# ------------------ HELPERS ------------------\n",
    "def read_results_txt(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Lee el .txt, tipa columnas y devuelve DataFrame con NaNs donde toque.\"\"\"\n",
    "    df = pd.read_csv(path, comment=\"#\", header=None, names=COLS)\n",
    "    df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], errors=\"coerce\")\n",
    "    num = [\"window_size_s\",\"num_windows\",\"time_peak_to_peak_amp\",\n",
    "           \"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"]\n",
    "    df[num] = df[num].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def label_from_window(df: pd.DataFrame, filename: str) -> str:\n",
    "    \"\"\"Etiqueta limpia tipo '8s', '15s', '30s'.\"\"\"\n",
    "    if df[\"window_size_s\"].notna().any():\n",
    "        try:\n",
    "            v = int(round(float(df[\"window_size_s\"].dropna().iloc[0])))\n",
    "            return f\"{v}s\"\n",
    "        except Exception:\n",
    "            pass\n",
    "    for cand in (\"8\",\"15\",\"30\"):\n",
    "        if cand in os.path.basename(filename):\n",
    "            return f\"{cand}s\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def add_textbox(fig, text, x=0.02, y=0.04):\n",
    "    \"\"\"Caja de texto pegada a la esquina inferior-izquierda.\"\"\"\n",
    "    fig.text(x, y, text, fontsize=14,\n",
    "             bbox=dict(facecolor=\"white\", alpha=0.95, edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "\n",
    "def simple_linear_regression(x, y):\n",
    "    \"\"\"Ajuste y = a + b·x. Devuelve (a, b, R²).\"\"\"\n",
    "    x = np.asarray(x, float); y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[m], y[m]\n",
    "    if x.size < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    b, a = np.polyfit(x, y, 1)  # slope=b, intercept=a\n",
    "    yhat = a + b*x\n",
    "    ss_res = np.sum((y - yhat)**2)\n",
    "    ss_tot = np.sum((y - np.mean(y))**2)\n",
    "    r2 = np.nan if ss_tot == 0 else 1 - ss_res/ss_tot\n",
    "    return a, b, r2\n",
    "\n",
    "# ------------------ BUCLE PRINCIPAL ------------------\n",
    "for path in INPUT_FILES:\n",
    "    df = read_results_txt(path)\n",
    "    win_label = label_from_window(df, path)\n",
    "\n",
    "    # Preview para verificar columnas correctas\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"File: {os.path.basename(path)} | window: {win_label}\")\n",
    "    print(df[[\"multi_harmonics_peak\", \"first_harmonic_peak\"]].head())\n",
    "\n",
    "    # Datos\n",
    "    first = df[\"first_harmonic_peak\"].to_numpy(dtype=float)\n",
    "    multi = df[\"multi_harmonics_peak\"].to_numpy(dtype=float)\n",
    "    ratio = multi / np.where(first == 0, np.nan, first)\n",
    "\n",
    "    # ------------------ (1) HISTOGRAMA DE R ------------------\n",
    "    valid_R = ratio[np.isfinite(ratio)]\n",
    "    if valid_R.size > 0:\n",
    "        fig = plt.figure(figsize=(14, 8))\n",
    "        ax = plt.gca()\n",
    "\n",
    "        # Histograma\n",
    "        bins = max(10, int(np.sqrt(valid_R.size)))\n",
    "        ax.hist(valid_R, bins=bins, alpha=0.85, label=\"Ratio R\")\n",
    "\n",
    "        # Estadísticos\n",
    "        mean_R   = float(np.nanmean(valid_R))\n",
    "        median_R = float(np.nanmedian(valid_R))\n",
    "        q25      = float(np.nanpercentile(valid_R, 25))\n",
    "        q75      = float(np.nanpercentile(valid_R, 75))\n",
    "        std_R    = float(np.nanstd(valid_R, ddof=1))\n",
    "\n",
    "        # Líneas guía\n",
    "        ax.axvline(1.0, linestyle=\"--\", linewidth=1, label=\"Identity R=1\")\n",
    "        ax.axvline(mean_R, linestyle=\"-\", linewidth=1, label=\"Mean\")\n",
    "        ax.axvline(median_R, linestyle=\":\", linewidth=1, label=\"Median\")\n",
    "\n",
    "        ax.set_xlabel(\"Energy ratio  R = multi_harmonics_peak / first_harmonic_peak\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(f\"Distribution of R — {win_label}\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        txt = (f\"n = {valid_R.size}\\n\"\n",
    "               f\"mean = {mean_R:.3f}   median = {median_R:.3f}\\n\"\n",
    "               f\"std = {std_R:.3f}   Q25 = {q25:.3f}   Q75 = {q75:.3f}\")\n",
    "        add_textbox(fig, txt)\n",
    "\n",
    "        # 👇 Leyenda fuera y centrada abajo\n",
    "        ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=3, frameon=True)\n",
    "        plt.subplots_adjust(bottom=0.28)\n",
    "\n",
    "        out_png = os.path.join(OUTPUT_DIR, f\"hist_ratio_R_{win_label}.png\")\n",
    "        plt.savefig(out_png, bbox_inches=\"tight\"); plt.close()\n",
    "        print(\"Saved:\", out_png)\n",
    "\n",
    "    # ------------------ (2) DISPERSIÓN multi vs first ------------------\n",
    "    mask = np.isfinite(first) & np.isfinite(multi)\n",
    "    xf = first[mask]; yf = multi[mask]\n",
    "\n",
    "    if xf.size >= 2:\n",
    "        r, pval = pearsonr(xf, yf)\n",
    "        a, b, r2 = simple_linear_regression(xf, yf)\n",
    "\n",
    "        lim = float(np.nanmax([xf.max(), yf.max(), 0.0])) * 1.05\n",
    "\n",
    "        fig = plt.figure(figsize=(14, 8))\n",
    "        ax = plt.gca()\n",
    "\n",
    "        ax.scatter(xf, yf, s=70, label=\"Fragments\")\n",
    "        # Línea identidad\n",
    "        ax.plot([0, lim], [0, lim], linestyle=\"--\", linewidth=1, label=\"Identity y=x\")\n",
    "        # Línea regresión\n",
    "        if not (math.isnan(a) or math.isnan(b)):\n",
    "            xline = np.linspace(0, lim, 200)\n",
    "            yline = a + b * xline\n",
    "            ax.plot(xline, yline, linestyle=\"-\", linewidth=1, label=\"Linear fit\")\n",
    "\n",
    "        ax.set_xlabel(\"First harmonic peak (mmHg)\")\n",
    "        ax.set_ylabel(\"Multi-harmonics peak (mmHg)\")\n",
    "        ax.set_title(f\"multi vs first — {win_label}\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 👇 Leyenda fuera, centrada abajo\n",
    "        ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=3, frameon=True)\n",
    "        plt.subplots_adjust(bottom=0.28)\n",
    "\n",
    "        txt = (f\"Pearson r = {r:.3f},  p = {pval:.3g}\\n\"\n",
    "               f\"Fit: y = a + b·x   a = {a:.3f},  b = {b:.3f}\\n\"\n",
    "               f\"R² = {r2:.3f}\")\n",
    "        add_textbox(fig, txt)\n",
    "\n",
    "        out_png = os.path.join(OUTPUT_DIR, f\"scatter_multi_vs_first_{win_label}.png\")\n",
    "        plt.savefig(out_png, bbox_inches=\"tight\"); plt.close()\n",
    "        print(\"Saved:\", out_png)\n",
    "\n",
    "print(\"\\nListo. Revisa la carpeta:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d563c4",
   "metadata": {},
   "source": [
    "Third analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "942bb390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "File: final_results_window8.txt | window: 8s\n",
      "   patient   fragment  time_peak_to_peak_amp  multi_harmonics_peak  candidate_multi_x2\n",
      " paciente1 fragmento1                  0.800                 0.271               0.542\n",
      " paciente1 fragmento2                  0.787                 0.263               0.526\n",
      " paciente1 fragmento3                  0.727                 0.261               0.522\n",
      "paciente10 fragmento1                  6.255                 2.033               4.066\n",
      "paciente10 fragmento2                 10.456                 3.642               7.284\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "File: final_results_window15.txt | window: 15s\n",
      "   patient   fragment  time_peak_to_peak_amp  multi_harmonics_peak  candidate_multi_x2\n",
      " paciente1 fragmento1                  0.799                 0.237               0.474\n",
      " paciente1 fragmento2                  0.786                 0.222               0.444\n",
      " paciente1 fragmento3                  0.726                 0.220               0.440\n",
      "paciente10 fragmento1                  6.305                 1.815               3.630\n",
      "paciente10 fragmento2                 10.464                 3.329               6.658\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "File: final_results_window30.txt | window: 30s\n",
      "   patient   fragment  time_peak_to_peak_amp  multi_harmonics_peak  candidate_multi_x2\n",
      " paciente1 fragmento1                  0.798                 0.167               0.334\n",
      " paciente1 fragmento2                  0.790                 0.177               0.354\n",
      " paciente1 fragmento3                  0.729                 0.166               0.332\n",
      "paciente10 fragmento1                  6.306                 1.428               2.856\n",
      "paciente10 fragmento2                 10.464                 2.832               5.664\n",
      "\n",
      "Saved in: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\stat_results.xlsx  [sheet: analysis3_multiX2_vs_time]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Analysis 3 — Compare (2 * multi_harmonics_peak) vs time P2P\n",
    "#   - Uses the three TXT inputs (8s, 15s, 30s)\n",
    "#   - Writes to the same Excel as Analyses 1 & 2, new sheet\n",
    "#   - Prints previews to verify correct columns\n",
    "# ============================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# ------------------ INPUT / OUTPUT ------------------\n",
    "INPUT_FILES = [\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window8.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window15.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window30.txt\",\n",
    "]\n",
    "OUTPUT_XLSX = r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\stat_results.xlsx\"\n",
    "SHEET_NAME = \"analysis3_multiX2_vs_time\"\n",
    "\n",
    "# Columns present in the TXT results\n",
    "COLS = [\n",
    "    \"patient\",\"fragment\",\"start_time\",\"unit\",\"window_size_s\",\"num_windows\",\n",
    "    \"time_peak_to_peak_amp\",\"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"\n",
    "]\n",
    "\n",
    "# ------------------ HELPERS ------------------\n",
    "def ensure_dir_for(path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "def read_results(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read the results .txt, coerce dtypes, keep NaNs if any.\"\"\"\n",
    "    df = pd.read_csv(path, comment=\"#\", header=None, names=COLS)\n",
    "    df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], errors=\"coerce\")\n",
    "    num_cols = [\n",
    "        \"window_size_s\",\"num_windows\",\"time_peak_to_peak_amp\",\n",
    "        \"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"\n",
    "    ]\n",
    "    df[num_cols] = df[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    # Order rows to keep outputs stable and readable\n",
    "    df = df.sort_values([\"patient\",\"fragment\",\"start_time\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def bland_altman(x, y):\n",
    "    \"\"\"Return BA stats for diff = (y - x).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    d = y[m] - x[m]\n",
    "    if d.size == 0:\n",
    "        return {\"bias\": np.nan, \"sd\": np.nan, \"loa_low\": np.nan, \"loa_high\": np.nan}\n",
    "    bias = float(np.nanmean(d))\n",
    "    sd   = float(np.nanstd(d, ddof=1))\n",
    "    return {\n",
    "        \"bias\": bias,\n",
    "        \"sd\": sd,\n",
    "        \"loa_low\": bias - 1.96*sd,\n",
    "        \"loa_high\": bias + 1.96*sd\n",
    "    }\n",
    "\n",
    "def simple_linear_regression(x, y):\n",
    "    \"\"\"\n",
    "    Fit y = a + b*x on finite pairs.\n",
    "    Returns dict(intercept=a, slope=b, r2).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[m], y[m]\n",
    "    if x.size < 2:\n",
    "        return {\"intercept\": np.nan, \"slope\": np.nan, \"r2\": np.nan}\n",
    "    b, a = np.polyfit(x, y, 1)  # slope=b, intercept=a\n",
    "    yhat = a + b*x\n",
    "    ss_res = float(np.sum((y - yhat)**2))\n",
    "    ss_tot = float(np.sum((y - np.nanmean(y))**2))\n",
    "    r2 = np.nan if ss_tot == 0 else 1 - ss_res/ss_tot\n",
    "    return {\"intercept\": float(a), \"slope\": float(b), \"r2\": float(r2)}\n",
    "\n",
    "# ------------------ MAIN LOOP ------------------\n",
    "all_rows = []\n",
    "summary_rows = []\n",
    "\n",
    "for path in INPUT_FILES:\n",
    "    df = read_results(path)\n",
    "\n",
    "    # Window label (e.g., '8s', '15s', '30s')\n",
    "    win = int(df[\"window_size_s\"].iloc[0]) if not df[\"window_size_s\"].isna().all() else None\n",
    "    window_label = f\"{win}s\" if win is not None else \"unknown\"\n",
    "\n",
    "    # Reference (time) and candidate (frequency-based estimate)\n",
    "    ref_time = df[\"time_peak_to_peak_amp\"]\n",
    "    cand_multi_x2 = 2.0 * df[\"multi_harmonics_peak\"]\n",
    "\n",
    "    # ------- PREVIEW: show first rows to verify we picked right columns -------\n",
    "    print(\"\\n\" + \"-\"*90)\n",
    "    print(f\"File: {os.path.basename(path)} | window: {window_label}\")\n",
    "    preview = pd.DataFrame({\n",
    "        \"patient\": df[\"patient\"].head(5),\n",
    "        \"fragment\": df[\"fragment\"].head(5),\n",
    "        \"time_peak_to_peak_amp\": ref_time.head(5),\n",
    "        \"multi_harmonics_peak\": df[\"multi_harmonics_peak\"].head(5),\n",
    "        \"candidate_multi_x2\": cand_multi_x2.head(5)\n",
    "    })\n",
    "    print(preview.to_string(index=False))\n",
    "\n",
    "    # ------- Row-wise metrics -------\n",
    "    rows = df[[\"patient\",\"fragment\",\"start_time\",\"unit\",\"window_size_s\"]].copy()\n",
    "    rows[\"time_peak_to_peak_amp\"] = ref_time\n",
    "    rows[\"candidate_multi_x2\"]    = cand_multi_x2\n",
    "    rows[\"abs_diff\"] = (cand_multi_x2 - ref_time).abs()\n",
    "    rows[\"rel_error_pct\"] = 100.0 * (cand_multi_x2 - ref_time) / ref_time.replace(0, np.nan)\n",
    "    rows[\"source_file\"]  = os.path.basename(path)\n",
    "    rows[\"window_label\"] = window_label\n",
    "    all_rows.append(rows)\n",
    "\n",
    "    # ------- Summary-by-window (valid pairs only) -------\n",
    "    valid = rows[[\"time_peak_to_peak_amp\",\"candidate_multi_x2\"]].dropna()\n",
    "    if len(valid) >= 2:\n",
    "        r, p = pearsonr(valid[\"time_peak_to_peak_amp\"], valid[\"candidate_multi_x2\"])\n",
    "        ba   = bland_altman(valid[\"time_peak_to_peak_amp\"].to_numpy(),\n",
    "                            valid[\"candidate_multi_x2\"].to_numpy())\n",
    "        reg  = simple_linear_regression(valid[\"candidate_multi_x2\"].to_numpy(),\n",
    "                                        valid[\"time_peak_to_peak_amp\"].to_numpy())\n",
    "    else:\n",
    "        r = p = np.nan\n",
    "        ba = {\"bias\": np.nan, \"sd\": np.nan, \"loa_low\": np.nan, \"loa_high\": np.nan}\n",
    "        reg = {\"intercept\": np.nan, \"slope\": np.nan, \"r2\": np.nan}\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"window_label\": window_label,\n",
    "        \"n_pairs\": len(valid),\n",
    "        \"pearson_r\": r,\n",
    "        \"pearson_p_value\": p,\n",
    "        \"bland_altman_bias_mmHg\": ba[\"bias\"],\n",
    "        \"bland_altman_sd_diff_mmHg\": ba[\"sd\"],\n",
    "        \"bland_altman_loa_low_mmHg\": ba[\"loa_low\"],\n",
    "        \"bland_altman_loa_high_mmHg\": ba[\"loa_high\"],\n",
    "        \"mean_abs_diff_mmHg\": (valid[\"candidate_multi_x2\"] - valid[\"time_peak_to_peak_amp\"]).abs().mean(),\n",
    "        \"median_abs_diff_mmHg\": (valid[\"candidate_multi_x2\"] - valid[\"time_peak_to_peak_amp\"]).abs().median(),\n",
    "        \"mean_rel_error_pct\": (\n",
    "            100.0 * (valid[\"candidate_multi_x2\"] - valid[\"time_peak_to_peak_amp\"])\n",
    "            / valid[\"time_peak_to_peak_amp\"]\n",
    "        ).mean(),\n",
    "        \"linreg_intercept\": reg[\"intercept\"],\n",
    "        \"linreg_slope\": reg[\"slope\"],\n",
    "        \"linreg_r2\": reg[\"r2\"],\n",
    "    })\n",
    "\n",
    "# ------------------ BUILD TABLES ------------------\n",
    "all_rows_df        = pd.concat(all_rows, ignore_index=True)\n",
    "summary_by_window  = pd.DataFrame(summary_rows)\n",
    "\n",
    "# ------------------ WRITE EXCEL (new sheet, clean) ------------------\n",
    "ensure_dir_for(OUTPUT_XLSX)\n",
    "\n",
    "# If workbook exists and the sheet already exists, remove it to start clean\n",
    "if os.path.exists(OUTPUT_XLSX):\n",
    "    wb = load_workbook(OUTPUT_XLSX)\n",
    "    if SHEET_NAME in wb.sheetnames:\n",
    "        ws = wb[SHEET_NAME]\n",
    "        wb.remove(ws)\n",
    "        wb.save(OUTPUT_XLSX)\n",
    "    wb.close()\n",
    "    mode = \"a\"\n",
    "else:\n",
    "    mode = \"w\"\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\", mode=mode, if_sheet_exists=\"overlay\") as writer:\n",
    "    # Detailed rows\n",
    "    all_rows_df.to_excel(writer, sheet_name=SHEET_NAME, index=False)\n",
    "\n",
    "    # Title + summary placed below the detail table\n",
    "    ws = writer.sheets[SHEET_NAME]\n",
    "    startrow = all_rows_df.shape[0] + 2  # one blank line\n",
    "    ws.cell(row=startrow, column=1, value=\"SUMMARY_BY_WINDOW (Analysis 3)\")\n",
    "    # Summary table two lines below the title\n",
    "    summary_by_window.to_excel(writer, sheet_name=SHEET_NAME, index=False, startrow=startrow + 2)\n",
    "\n",
    "print(f\"\\nSaved in: {OUTPUT_XLSX}  [sheet: {SHEET_NAME}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb432de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "File: final_results_window8.txt | window: 8s\n",
      "   patient   fragment  time_P2P  multi  candidate_multi_x2\n",
      "paciente20 fragmento1     4.850  1.635               3.270\n",
      "paciente20 fragmento2     5.910  1.929               3.858\n",
      "paciente20 fragmento3     5.014  1.761               3.522\n",
      " paciente3 fragmento1     8.480  3.344               6.688\n",
      " paciente3 fragmento2     8.189  3.417               6.834\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "File: final_results_window15.txt | window: 15s\n",
      "   patient   fragment  time_P2P  multi  candidate_multi_x2\n",
      "paciente20 fragmento1     4.835  1.486               2.972\n",
      "paciente20 fragmento2     5.877  1.932               3.864\n",
      "paciente20 fragmento3     5.016  1.711               3.422\n",
      " paciente3 fragmento1     8.635  3.085               6.170\n",
      " paciente3 fragmento2     8.191  3.227               6.454\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "File: final_results_window30.txt | window: 30s\n",
      "   patient   fragment  time_P2P  multi  candidate_multi_x2\n",
      "paciente20 fragmento1     4.847  1.295               2.590\n",
      "paciente20 fragmento2     5.878  1.786               3.572\n",
      "paciente20 fragmento3     5.010  1.377               2.754\n",
      " paciente3 fragmento1     8.666  2.926               5.852\n",
      " paciente3 fragmento2     8.263  2.770               5.540\n",
      "Done. Figures saved in: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS3\n",
      "PDF multipage: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS3\\analysis3_visuals_by_window.pdf\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Analysis 3 — Visualizations\n",
    "#   Compare: Time P2P (reference) vs Candidate = 2 * multi_harmonics_peak\n",
    "#   For each window (8s, 15s, 30s) it creates:\n",
    "#     (1) Paired per fragment\n",
    "#     (2) Scatter with identity + linear regression\n",
    "#     (3) Bland–Altman (candidate - reference)\n",
    "#   Sources: original TXT files (no Excel needed)\n",
    "# ============================================================\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# ------------------ PATHS ------------------\n",
    "INPUT_FILES = [\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window8.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window15.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window30.txt\",\n",
    "]\n",
    "OUTPUT_DIR = r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS3\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------ STYLE (large and readable) ------------------\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 120,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"font.size\": 18,\n",
    "    \"axes.titlesize\": 24,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "})\n",
    "\n",
    "# ------------------ TXT COLUMNS ------------------\n",
    "COLS = [\n",
    "    \"patient\",\"fragment\",\"start_time\",\"unit\",\"window_size_s\",\"num_windows\",\n",
    "    \"time_peak_to_peak_amp\",\"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"\n",
    "]\n",
    "\n",
    "# ------------------ HELPERS ------------------\n",
    "def read_results_txt(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read TXT, coerce dtypes, keep NaNs if any, and sort for stable plots.\"\"\"\n",
    "    df = pd.read_csv(path, comment=\"#\", header=None, names=COLS)\n",
    "    df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], errors=\"coerce\")\n",
    "    num = [\"window_size_s\",\"num_windows\",\"time_peak_to_peak_amp\",\n",
    "           \"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"]\n",
    "    df[num] = df[num].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df = df.sort_values([\"start_time\",\"patient\",\"fragment\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def label_from_window(df: pd.DataFrame, filename: str) -> str:\n",
    "    \"\"\"Return clean label like '8s', '15s', '30s'.\"\"\"\n",
    "    if df[\"window_size_s\"].notna().any():\n",
    "        try:\n",
    "            v = int(round(float(df[\"window_size_s\"].dropna().iloc[0])))\n",
    "            return f\"{v}s\"\n",
    "        except Exception:\n",
    "            pass\n",
    "    for cand in (\"8\",\"15\",\"30\"):\n",
    "        if cand in os.path.basename(filename):\n",
    "            return f\"{cand}s\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def add_textbox(fig, text, x=0.02, y=0.04):\n",
    "    \"\"\"Readable annotation box near lower-left corner.\"\"\"\n",
    "    fig.text(x, y, text, fontsize=16,\n",
    "             bbox=dict(facecolor=\"white\", alpha=0.95, edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "\n",
    "def place_legend_below(ax, ncol=2):\n",
    "    \"\"\"Place legend outside, centered below, with extra bottom margin.\"\"\"\n",
    "    plt.subplots_adjust(bottom=0.28)\n",
    "    ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.18), ncol=ncol, frameon=True)\n",
    "\n",
    "def bland_altman_stats(x, y):\n",
    "    \"\"\"Return (bias, sd, loa_low, loa_high) for diff = (y - x).\"\"\"\n",
    "    x = np.asarray(x, float); y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    d = y[m] - x[m]\n",
    "    if d.size == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    bias = float(np.nanmean(d))\n",
    "    sd   = float(np.nanstd(d, ddof=1))\n",
    "    return bias, sd, bias - 1.96*sd, bias + 1.96*sd\n",
    "\n",
    "def simple_linear_regression(x, y):\n",
    "    \"\"\"Fit y = a + b·x. Return (a, b, R²).\"\"\"\n",
    "    x = np.asarray(x, float); y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[m], y[m]\n",
    "    if x.size < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    b, a = np.polyfit(x, y, 1)  # slope=b, intercept=a\n",
    "    yhat = a + b*x\n",
    "    ss_res = float(np.sum((y - yhat)**2))\n",
    "    ss_tot = float(np.sum((y - np.mean(y))**2))\n",
    "    r2 = np.nan if ss_tot == 0 else 1 - ss_res/ss_tot\n",
    "    return a, b, r2\n",
    "\n",
    "# ------------------ MAIN LOOP ------------------\n",
    "png_paths = []\n",
    "\n",
    "for path in INPUT_FILES:\n",
    "    df = read_results_txt(path)\n",
    "    win_label = label_from_window(df, path)\n",
    "\n",
    "    # Data\n",
    "    time_p2p = df[\"time_peak_to_peak_amp\"].to_numpy(dtype=float)           # reference\n",
    "    multi    = df[\"multi_harmonics_peak\"].to_numpy(dtype=float)\n",
    "    cand     = 2.0 * multi                                                # candidate = 2 * multi_harmonics_peak\n",
    "\n",
    "    # ------- Preview: first rows to verify columns -------\n",
    "    print(\"\\n\" + \"-\"*90)\n",
    "    print(f\"File: {os.path.basename(path)} | window: {win_label}\")\n",
    "    print(pd.DataFrame({\n",
    "        \"patient\":  df[\"patient\"].head(5),\n",
    "        \"fragment\": df[\"fragment\"].head(5),\n",
    "        \"time_P2P\": df[\"time_peak_to_peak_amp\"].head(5),\n",
    "        \"multi\":    df[\"multi_harmonics_peak\"].head(5),\n",
    "        \"candidate_multi_x2\": (2.0 * df[\"multi_harmonics_peak\"]).head(5)\n",
    "    }).to_string(index=False))\n",
    "\n",
    "    # ------------------ (1) PAIRED PER FRAGMENT ------------------\n",
    "    x_idx = np.arange(len(df))\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # connect pairs\n",
    "    for i in range(len(x_idx)):\n",
    "        ax.plot([x_idx[i], x_idx[i]], [time_p2p[i], cand[i]], linewidth=1)\n",
    "\n",
    "    ax.scatter(x_idx, time_p2p, s=70, label=\"Time P2P (mmHg)\")\n",
    "    ax.scatter(x_idx, cand,     s=70, label=\"Candidate: 2 × multi (mmHg)\")\n",
    "\n",
    "    ax.set_xlabel(\"Fragments ordered by start_time\")\n",
    "    ax.set_ylabel(\"Amplitude (mmHg)\")\n",
    "    ax.set_title(f\"Paired comparison per fragment — {win_label}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    place_legend_below(ax, ncol=2)\n",
    "\n",
    "    # stats box\n",
    "    abs_diff = np.abs(cand - time_p2p)\n",
    "    rel_err  = 100.0 * (cand - time_p2p) / np.where(time_p2p == 0, np.nan, time_p2p)\n",
    "    bias, sd, loa_low, loa_high = bland_altman_stats(time_p2p, cand)\n",
    "    txt = (f\"Mean |diff| = {np.nanmean(abs_diff):.3f} mmHg   \"\n",
    "           f\"Median |diff| = {np.nanmedian(abs_diff):.3f} mmHg\\n\"\n",
    "           f\"Mean rel. error = {np.nanmean(rel_err):.1f}%   \"\n",
    "           f\"Bias = {bias:.3f} mmHg,  LoA = [{loa_low:.3f}, {loa_high:.3f}] mmHg\")\n",
    "    add_textbox(fig, txt, x=0.02, y=0.04)\n",
    "\n",
    "    out1 = os.path.join(OUTPUT_DIR, f\"01_paired_per_fragment_multiX2_{win_label}.png\")\n",
    "    plt.savefig(out1, bbox_inches=\"tight\"); plt.close(); png_paths.append(out1)\n",
    "\n",
    "    # ------------------ (2) SCATTER + IDENTITY + REGRESSION ------------------\n",
    "    mask = np.isfinite(time_p2p) & np.isfinite(cand)\n",
    "    r, pval = (np.nan, np.nan)\n",
    "    if mask.sum() >= 2:\n",
    "        r, pval = pearsonr(time_p2p[mask], cand[mask])\n",
    "        a, b, r2 = simple_linear_regression(time_p2p, cand)\n",
    "    else:\n",
    "        a = b = r2 = np.nan\n",
    "\n",
    "    lim = float(np.nanmax([np.nanmax(time_p2p), np.nanmax(cand), 0.0]))\n",
    "    lim = lim * 1.05 if np.isfinite(lim) and lim > 0 else 1.0\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    ax.scatter(time_p2p, cand, s=70)\n",
    "    # identity\n",
    "    ax.plot([0, lim], [0, lim], linestyle=\"--\", linewidth=1, label=\"Identity\")\n",
    "    # regression\n",
    "    if not (math.isnan(a) or math.isnan(b)):\n",
    "        xline = np.linspace(0, lim, 200)\n",
    "        yline = a + b * xline\n",
    "        ax.plot(xline, yline, linestyle=\"-\", linewidth=1, label=\"Linear fit\")\n",
    "\n",
    "    ax.set_xlabel(\"Time peak-to-peak amplitude (mmHg)\")\n",
    "    ax.set_ylabel(\"Candidate: 2 × multi_harmonics_peak (mmHg)\")\n",
    "    ax.set_title(f\"Time vs Candidate (2×multi) — {win_label}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    place_legend_below(ax, ncol=2)\n",
    "\n",
    "    txt = (f\"Pearson r = {r:.3f},  p = {pval:.3g}\\n\"\n",
    "           f\"Fit: y = a + b·x   a = {a:.3f},  b = {b:.3f}\\n\"\n",
    "           f\"R² = {r2:.3f}\")\n",
    "    add_textbox(fig, txt, x=0.02, y=0.04)\n",
    "\n",
    "    out2 = os.path.join(OUTPUT_DIR, f\"02_scatter_time_vs_multiX2_{win_label}.png\")\n",
    "    plt.savefig(out2, bbox_inches=\"tight\"); plt.close(); png_paths.append(out2)\n",
    "\n",
    "    # ------------------ (3) BLAND–ALTMAN ------------------\n",
    "    bias, sd, loa_low, loa_high = bland_altman_stats(time_p2p, cand)\n",
    "    mean_xy = (time_p2p + cand) / 2.0\n",
    "    diff    = cand - time_p2p\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = plt.gca()\n",
    "    ax.scatter(mean_xy, diff, s=70)\n",
    "    ax.axhline(bias,     linestyle=\"-\",  linewidth=1, label=f\"Bias {bias:.3f}\")\n",
    "    ax.axhline(loa_low,  linestyle=\"--\", linewidth=1, label=f\"LoA low {loa_low:.3f}\")\n",
    "    ax.axhline(loa_high, linestyle=\"--\", linewidth=1, label=f\"LoA high {loa_high:.3f}\")\n",
    "\n",
    "    ax.set_xlabel(\"Mean of methods (mmHg)\")\n",
    "    ax.set_ylabel(\"Difference (candidate - time) (mmHg)\")\n",
    "    ax.set_title(f\"Bland–Altman — {win_label}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    place_legend_below(ax, ncol=3)\n",
    "\n",
    "    txt = (f\"Bias = {bias:.3f} mmHg   SD = {sd:.3f} mmHg\\n\"\n",
    "           f\"LoA = [{loa_low:.3f}, {loa_high:.3f}] mmHg\")\n",
    "    add_textbox(fig, txt, x=0.02, y=0.04)\n",
    "\n",
    "    out3 = os.path.join(OUTPUT_DIR, f\"03_bland_altman_multiX2_{win_label}.png\")\n",
    "    plt.savefig(out3, bbox_inches=\"tight\"); plt.close(); png_paths.append(out3)\n",
    "\n",
    "# ------------------ MULTI-PAGE PDF ------------------\n",
    "pdf_path = os.path.join(OUTPUT_DIR, \"analysis3_visuals_by_window.pdf\")\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    for p in png_paths:\n",
    "        img = plt.imread(p)\n",
    "        plt.figure(figsize=(11.69, 8.27))  # A4 landscape\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        pdf.savefig(bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "print(\"Done. Figures saved in:\", OUTPUT_DIR)\n",
    "print(\"PDF multipage:\", pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50a633",
   "metadata": {},
   "source": [
    "Fourth analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab0884da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "File: final_results_window8.txt | window: 8s\n",
      "Preview of metrics (first 5 rows):\n",
      " time_peak_to_peak_amp  first_harmonic_peak  first_harmonic_p2p  multi_harmonics_peak\n",
      "                 0.800                0.259               0.517                 0.271\n",
      "                 0.787                0.246               0.491                 0.263\n",
      "                 0.727                0.247               0.493                 0.261\n",
      "                 6.255                1.925               3.850                 2.033\n",
      "                10.456                3.464               6.929                 3.642\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "File: final_results_window15.txt | window: 15s\n",
      "Preview of metrics (first 5 rows):\n",
      " time_peak_to_peak_amp  first_harmonic_peak  first_harmonic_p2p  multi_harmonics_peak\n",
      "                 0.799                0.227               0.455                 0.237\n",
      "                 0.786                0.211               0.423                 0.222\n",
      "                 0.726                0.209               0.419                 0.220\n",
      "                 6.305                1.745               3.491                 1.815\n",
      "                10.464                3.194               6.388                 3.329\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "File: final_results_window30.txt | window: 30s\n",
      "Preview of metrics (first 5 rows):\n",
      " time_peak_to_peak_amp  first_harmonic_peak  first_harmonic_p2p  multi_harmonics_peak\n",
      "                 0.798                0.161               0.321                 0.167\n",
      "                 0.790                0.169               0.338                 0.177\n",
      "                 0.729                0.160               0.319                 0.166\n",
      "                 6.306                1.371               2.741                 1.428\n",
      "                10.464                2.724               5.447                 2.832\n",
      "Figures saved in: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS4\n",
      "PDF multipage: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS4\\analysis4_heatmaps_and_scatters.pdf\n",
      "\n",
      "Saved Excel: C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\stat_results.xlsx  [sheet: analysis4_correlations]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Analysis 4 — Correlation matrix + strong-pair scatters\n",
    "#   - Works per window (8s, 15s, 30s) from your TXT sources\n",
    "#   - Metrics: time_peak_to_peak_amp, first_harmonic_peak,\n",
    "#              first_harmonic_p2p, multi_harmonics_peak\n",
    "#   - Optional EXTENDED mode adds candidate_multi_x2 = 2 * multi_harmonics_peak\n",
    "#   - Outputs:\n",
    "#       * Heatmap PNGs per window\n",
    "#       * Scatter PNGs for strongest pairs per window (identity + regression)\n",
    "#       * One multi-page PDF\n",
    "#       * Excel sheet \"analysis4_correlations\" in stat_results.xlsx\n",
    "# ============================================================\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# ------------------ PATHS ------------------\n",
    "INPUT_FILES = [\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window8.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window15.txt\",\n",
    "    r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\final_results_window30.txt\",\n",
    "]\n",
    "OUTPUT_DIR   = r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\figures_ANALYSIS4\"\n",
    "OUTPUT_XLSX  = r\"C:\\Users\\sofia\\OneDrive\\Escritorio\\TFGPython\\statistics\\stat_results.xlsx\"\n",
    "SHEET_NAME   = \"analysis4_correlations\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------ STYLE (large & readable) ------------------\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 120,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"font.size\": 18,\n",
    "    \"axes.titlesize\": 24,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 16,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "})\n",
    "\n",
    "# ------------------ TXT COLUMNS ------------------\n",
    "COLS = [\n",
    "    \"patient\",\"fragment\",\"start_time\",\"unit\",\"window_size_s\",\"num_windows\",\n",
    "    \"time_peak_to_peak_amp\",\"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"\n",
    "]\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "# If True, adds a 5th metric: candidate_multi_x2 = 2 * multi_harmonics_peak\n",
    "EXTENDED = False\n",
    "\n",
    "# Strong-pair selection policy for scatters\n",
    "TOP_K_PER_WINDOW = 3          # take top-K pairs by |Pearson r|\n",
    "MIN_ABS_R        = 0.85       # require at least this absolute r\n",
    "\n",
    "# ------------------ HELPERS ------------------\n",
    "def ensure_dir_for(path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "def read_results_txt(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read TXT, coerce dtypes, sort for stable output.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, comment=\"#\", header=None, names=COLS)\n",
    "    df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], errors=\"coerce\")\n",
    "    num = [\"window_size_s\",\"num_windows\",\"time_peak_to_peak_amp\",\n",
    "           \"first_harmonic_peak\",\"first_harmonic_p2p\",\"multi_harmonics_peak\"]\n",
    "    df[num] = df[num].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df = df.sort_values([\"patient\",\"fragment\",\"start_time\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def label_from_window(df: pd.DataFrame, filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Return clean label like '8s', '15s', '30s'.\n",
    "    \"\"\"\n",
    "    if df[\"window_size_s\"].notna().any():\n",
    "        try:\n",
    "            v = int(round(float(df[\"window_size_s\"].dropna().iloc[0])))\n",
    "            return f\"{v}s\"\n",
    "        except Exception:\n",
    "            pass\n",
    "    for cand in (\"8\",\"15\",\"30\"):\n",
    "        if cand in os.path.basename(filename):\n",
    "            return f\"{cand}s\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def simple_linear_regression(x, y):\n",
    "    \"\"\"\n",
    "    Fit y = a + b*x over finite pairs only. Return (a, b, R^2).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float)\n",
    "    y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[m], y[m]\n",
    "    if x.size < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    b, a = np.polyfit(x, y, 1)  # slope=b, intercept=a\n",
    "    yhat = a + b * x\n",
    "    ss_res = float(np.sum((y - yhat)**2))\n",
    "    ss_tot = float(np.sum((y - np.nanmean(y))**2))\n",
    "    r2 = np.nan if ss_tot == 0 else 1 - ss_res/ss_tot\n",
    "    return a, b, r2\n",
    "\n",
    "def compute_pairwise_corr(df_metrics: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Compute Pearson r (and p) and Spearman rho (and p) for all pairs.\n",
    "    Returns:\n",
    "        - corr_matrix_pearson: square DataFrame with Pearson r\n",
    "        - pairs_long: long table with rows per pair (i<j) containing stats\n",
    "    \"\"\"\n",
    "    cols = list(df_metrics.columns)\n",
    "    # Pearson matrix with pairwise complete observations\n",
    "    r_mat = pd.DataFrame(np.eye(len(cols)), index=cols, columns=cols, dtype=float)\n",
    "    pairs_rows = []\n",
    "\n",
    "    for i, j in itertools.combinations(range(len(cols)), 2):\n",
    "        xi = df_metrics.iloc[:, i].to_numpy(dtype=float)\n",
    "        yj = df_metrics.iloc[:, j].to_numpy(dtype=float)\n",
    "        m  = np.isfinite(xi) & np.isfinite(yj)\n",
    "        n  = int(m.sum())\n",
    "        if n >= 2:\n",
    "            r, p  = pearsonr(xi[m], yj[m])\n",
    "            rh, ph = spearmanr(xi[m], yj[m])\n",
    "        else:\n",
    "            r = p = rh = ph = np.nan\n",
    "\n",
    "        r_mat.iloc[i, j] = r\n",
    "        r_mat.iloc[j, i] = r\n",
    "\n",
    "        pairs_rows.append({\n",
    "            \"metric_x\": cols[i],\n",
    "            \"metric_y\": cols[j],\n",
    "            \"n\": n,\n",
    "            \"pearson_r\": r,\n",
    "            \"pearson_p\": p,\n",
    "            \"spearman_rho\": rh,\n",
    "            \"spearman_p\": ph,\n",
    "        })\n",
    "\n",
    "    corr_matrix_pearson = r_mat\n",
    "    pairs_long = pd.DataFrame(pairs_rows)\n",
    "    return corr_matrix_pearson, pairs_long\n",
    "\n",
    "def plot_heatmap(corr_df: pd.DataFrame, title: str, out_path: str):\n",
    "    \"\"\"\n",
    "    Simple heatmap with imshow and value annotations (no external libs).\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    data = corr_df.to_numpy(dtype=float)\n",
    "    im = ax.imshow(data, vmin=-1, vmax=1)  # default colormap\n",
    "\n",
    "    # Ticks / labels\n",
    "    ax.set_xticks(range(corr_df.shape[1]))\n",
    "    ax.set_yticks(range(corr_df.shape[0]))\n",
    "    ax.set_xticklabels(corr_df.columns, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(corr_df.index)\n",
    "\n",
    "    # Grid lines (light)\n",
    "    ax.set_xticks(np.arange(-0.5, corr_df.shape[1], 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, corr_df.shape[0], 1), minor=True)\n",
    "    ax.grid(which=\"minor\", linestyle=\"-\", linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    # Annotate r values\n",
    "    for i in range(corr_df.shape[0]):\n",
    "        for j in range(corr_df.shape[1]):\n",
    "            val = data[i, j]\n",
    "            if np.isfinite(val):\n",
    "                ax.text(j, i, f\"{val:.2f}\", ha=\"center\", va=\"center\", fontsize=12)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def place_legend_below(ax, ncol=2):\n",
    "    \"\"\"\n",
    "    Place legend outside, centered below, with extra bottom margin.\n",
    "    \"\"\"\n",
    "    plt.subplots_adjust(bottom=0.28)\n",
    "    ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.18), ncol=ncol, frameon=True)\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    \"\"\"Make a safe filename fragment from a metric name.\"\"\"\n",
    "    return s.replace(\" \", \"\").replace(\"/\", \"_\").replace(\"*\", \"x\")\n",
    "\n",
    "# ------------------ MAIN ------------------\n",
    "png_paths = []\n",
    "all_pairs_long = []          # long table across all windows\n",
    "all_top_pairs_summary = []   # which pairs were plotted per window\n",
    "corr_matrices_blocks = []    # (window_label, corr_matrix_pearson)\n",
    "\n",
    "for path in INPUT_FILES:\n",
    "    df = read_results_txt(path)\n",
    "    win_label = label_from_window(df, path)\n",
    "\n",
    "    # --- Choose metrics ---\n",
    "    metrics = [\n",
    "        \"time_peak_to_peak_amp\",\n",
    "        \"first_harmonic_peak\",\n",
    "        \"first_harmonic_p2p\",\n",
    "        \"multi_harmonics_peak\",\n",
    "    ]\n",
    "    df_metrics = df[metrics].copy()\n",
    "    if EXTENDED:\n",
    "        df_metrics[\"candidate_multi_x2\"] = 2.0 * df[\"multi_harmonics_peak\"]\n",
    "\n",
    "    # --- Preview to verify columns ---\n",
    "    print(\"\\n\" + \"-\"*90)\n",
    "    print(f\"File: {os.path.basename(path)} | window: {win_label}\")\n",
    "    print(\"Preview of metrics (first 5 rows):\")\n",
    "    print(df_metrics.head(5).to_string(index=False))\n",
    "\n",
    "    # --- Correlations ---\n",
    "    corr_matrix_pearson, pairs_long = compute_pairwise_corr(df_metrics)\n",
    "    pairs_long[\"window_label\"] = win_label\n",
    "    all_pairs_long.append(pairs_long)\n",
    "    corr_matrices_blocks.append((win_label, corr_matrix_pearson))\n",
    "\n",
    "    # --- Save heatmap ---\n",
    "    heatmap_png = os.path.join(OUTPUT_DIR, f\"heatmap_Pearson_{win_label}.png\")\n",
    "    plot_heatmap(corr_matrix_pearson, f\"Correlation (Pearson) — {win_label}\", heatmap_png)\n",
    "    png_paths.append(heatmap_png)\n",
    "\n",
    "    # --- Choose strongest pairs for scatters (by |r|) ---\n",
    "    # Filter by minimum |r| and n>=2, sort desc by |r|\n",
    "    pl = pairs_long.copy()\n",
    "    pl = pl[np.isfinite(pl[\"pearson_r\"])]\n",
    "    pl = pl[pl[\"n\"] >= 2]\n",
    "    pl[\"abs_r\"] = pl[\"pearson_r\"].abs()\n",
    "    pl = pl.sort_values(\"abs_r\", ascending=False)\n",
    "    pl = pl[pl[\"abs_r\"] >= MIN_ABS_R]\n",
    "    top_pairs = pl.head(TOP_K_PER_WINDOW)\n",
    "\n",
    "    # --- Generate scatter for selected pairs ---\n",
    "    for _, row in top_pairs.iterrows():\n",
    "        mx, my = row[\"metric_x\"], row[\"metric_y\"]\n",
    "        x = df_metrics[mx].to_numpy(dtype=float)\n",
    "        y = df_metrics[my].to_numpy(dtype=float)\n",
    "        mask = np.isfinite(x) & np.isfinite(y)\n",
    "        n = int(mask.sum())\n",
    "\n",
    "        if n < 2:\n",
    "            continue\n",
    "\n",
    "        r, p = pearsonr(x[mask], y[mask])\n",
    "        a, b, r2 = simple_linear_regression(x, y)\n",
    "\n",
    "        # axis limit\n",
    "        lim = float(np.nanmax([np.nanmax(x[mask]), np.nanmax(y[mask]), 0.0]))\n",
    "        lim = lim * 1.05 if np.isfinite(lim) and lim > 0 else 1.0\n",
    "\n",
    "        fig = plt.figure(figsize=(16, 9))\n",
    "        ax = plt.gca()\n",
    "\n",
    "        ax.scatter(x, y, s=70, label=\"Fragments\")\n",
    "        # Identity line\n",
    "        ax.plot([0, lim], [0, lim], linestyle=\"--\", linewidth=1, label=\"Identity\")\n",
    "        # Regression line\n",
    "        if not (math.isnan(a) or math.isnan(b)):\n",
    "            xline = np.linspace(0, lim, 200)\n",
    "            yline = a + b * xline\n",
    "            ax.plot(xline, yline, linestyle=\"-\", linewidth=1, label=\"Linear fit\")\n",
    "\n",
    "        ax.set_xlabel(mx)\n",
    "        ax.set_ylabel(my)\n",
    "        ax.set_title(f\"{mx} vs {my} — {win_label}\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        place_legend_below(ax, ncol=2)\n",
    "\n",
    "        txt = (f\"n = {n}\\n\"\n",
    "               f\"Pearson r = {r:.3f}, p = {p:.3g}\\n\"\n",
    "               f\"Fit: y = a + b·x   a = {a:.3f},  b = {b:.3f}\\n\"\n",
    "               f\"R² = {r2:.3f}\")\n",
    "        # Add small text box\n",
    "        fig.text(0.02, 0.04, txt, fontsize=16,\n",
    "                 bbox=dict(facecolor=\"white\", alpha=0.95, edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "\n",
    "        out_png = os.path.join(\n",
    "            OUTPUT_DIR, f\"scatter_{safe_name(mx)}_vs_{safe_name(my)}_{win_label}.png\"\n",
    "        )\n",
    "        plt.savefig(out_png, bbox_inches=\"tight\"); plt.close()\n",
    "        png_paths.append(out_png)\n",
    "\n",
    "        # Keep a summary row for the Excel sheet\n",
    "        all_top_pairs_summary.append({\n",
    "            \"window_label\": win_label,\n",
    "            \"metric_x\": mx,\n",
    "            \"metric_y\": my,\n",
    "            \"n\": n,\n",
    "            \"pearson_r\": r,\n",
    "            \"pearson_p\": p,\n",
    "            \"linreg_intercept\": a,\n",
    "            \"linreg_slope\": b,\n",
    "            \"linreg_r2\": r2,\n",
    "        })\n",
    "\n",
    "# ------------------ MULTI-PAGE PDF ------------------\n",
    "pdf_path = os.path.join(OUTPUT_DIR, \"analysis4_heatmaps_and_scatters.pdf\")\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    for p in png_paths:\n",
    "        img = plt.imread(p)\n",
    "        plt.figure(figsize=(11.69, 8.27))  # A4 landscape\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        pdf.savefig(bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "print(\"Figures saved in:\", OUTPUT_DIR)\n",
    "print(\"PDF multipage:\", pdf_path)\n",
    "\n",
    "# ------------------ WRITE EXCEL (single sheet for Analysis 4) ------------------\n",
    "ensure_dir_for(OUTPUT_XLSX)\n",
    "\n",
    "# Remove sheet if exists (clean start)\n",
    "if os.path.exists(OUTPUT_XLSX):\n",
    "    wb = load_workbook(OUTPUT_XLSX)\n",
    "    if SHEET_NAME in wb.sheetnames:\n",
    "        wb.remove(wb[SHEET_NAME])\n",
    "        wb.save(OUTPUT_XLSX)\n",
    "    wb.close()\n",
    "    mode = \"a\"\n",
    "else:\n",
    "    mode = \"w\"\n",
    "\n",
    "pairs_long_all = pd.concat(all_pairs_long, ignore_index=True)\n",
    "top_pairs_df   = pd.DataFrame(all_top_pairs_summary)\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\", mode=mode, if_sheet_exists=\"overlay\") as writer:\n",
    "    # 1) Long table with all pairs across windows\n",
    "    pairs_long_all.to_excel(writer, sheet_name=SHEET_NAME, index=False)\n",
    "\n",
    "    ws = writer.sheets[SHEET_NAME]\n",
    "    startrow = pairs_long_all.shape[0] + 2  # blank line\n",
    "\n",
    "    # 2) One block per window with the Pearson corr matrix\n",
    "    for win_label, cm in corr_matrices_blocks:\n",
    "        ws.cell(row=startrow, column=1, value=f\"CORR_MATRIX (Pearson) — {win_label}\")\n",
    "        cm.to_excel(writer, sheet_name=SHEET_NAME, startrow=startrow + 2)\n",
    "        startrow += cm.shape[0] + 4  # matrix rows + title+blank\n",
    "\n",
    "    # 3) Summary of top pairs plotted per window\n",
    "    ws.cell(row=startrow, column=1, value=\"TOP_PAIRS_BY_WINDOW (used for scatters)\")\n",
    "    top_pairs_df.to_excel(writer, sheet_name=SHEET_NAME, startrow=startrow + 2, index=False)\n",
    "\n",
    "print(f\"\\nSaved Excel: {OUTPUT_XLSX}  [sheet: {SHEET_NAME}]\")\n",
    "\n",
    "# ------------------ NOTES ------------------\n",
    "# - To include the extended metric candidate_multi_x2 in the correlation maps,\n",
    "#   set EXTENDED = True near the top of this script.\n",
    "# - You can tune TOP_K_PER_WINDOW and MIN_ABS_R to control how many scatter\n",
    "#   plots are generated and how strong the correlations should be.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd7696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgclean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
